# ----------------------------------------------------------------------
# HTM Community Edition of NuPIC
# Copyright (C) 2017, Numenta, Inc.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero Public License version 3 as
# published by the Free Software Foundation.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
# See the GNU Affero Public License for more details.
#
# You should have received a copy of the GNU Affero Public License
# along with this program.    If not, see http://www.gnu.org/licenses.
#
# http://numenta.org/licenses/
# ----------------------------------------------------------------------

"""
    This script creates simple experiment to compute the object classification
    accuracy of L2-L4-L6 network using objects from YCB dataset and "Thing" sensor
"""
import glob
import json
import logging
import os
import random
from collections import defaultdict, OrderedDict
import copy

import matplotlib
#matplotlib.use("Agg")
import matplotlib.pyplot as plt

import yaml
import experimentFramework.objectSpace as objectSpace
import experimentFramework.agent as agent
from experimentFramework.agent import Direction

import numpy as np
from htm.bindings.encoders import ScalarEncoder, ScalarEncoderParameters

from l2l4l6Framework.l2_l4_l6_Network import L2_L4_L6_Network
from htm.advanced.support.register_regions import registerAllAdvancedRegions

from utilities import (
    isNotebook,
    plotEnvironment,
    plotSensations)

logging.basicConfig(level=logging.WARN)

_EXEC_DIR = os.path.dirname(os.path.abspath(__file__))
# go one folder up and then into the objects folder
_OBJECTS_DIR = os.path.join(_EXEC_DIR, os.path.pardir, "objects")


PLOT_LEARN_SEQUENCE = False
PLOT_INFER_SEQUENCE = False

class Experiment:

    def __init__(self, objectSpaceSize):
        # create object space and the agent
        self.objectSpaceSize = objectSpaceSize
        self.objSpace = objectSpace.TwoDimensionalObjectSpace(objectSpaceSize, objectSpaceSize) # rectangle object space - "map"
        self.agent = agent.Agent()
        self.agent.set_objectSpace(self.objSpace, 0, 0)
        self.learnedObjects = {}

        self.bakePandaData = False # bake or not data for PandaVis

        self.fig_environment = None


    def loadObject(self, objectFilename):  # loads object into object space

        # load object from yml file
        with open(os.path.join(_OBJECTS_DIR, objectFilename+".yml"), "r") as stream:
            try:
                self.objSpace.load_object(stream)
            except yaml.YAMLError as exc:
                print(exc)

    """
    This will create sensation stream - array of positions in input space, generated by given algorithm
    :param n: The number of bits in the feature SDR. Usually L4 column count
    :type n: int
    :param w: Number of 'on' bits in the feature SDR. Usually L4 sample size
    :type w: int
    
    :return {'obj1' : [[[1,1,1],[101,205,523, ..., 1021]],...], ...}
    """
    def CreateSensationStream_positions(self, type = "all", sparsity = 0.5, featurePerc = 0.5 ): # this will create stream of pairs [location, sensation]

        row = list(range(0, self.objSpace.width))
        row_reverse = row.copy()
        row_reverse.reverse()

        # this simulates movement of the sensor like "snake" visiting each place in the space once
        # it is like: ------->|
        #             |<------ˇ
        #             ˇ------->
        # benefit is, that movement is continuous, with step size always 1
        pathx = np.concatenate([row if i % 2 == 0 else row_reverse for i in range(self.objSpace.height)])
        pathy = np.concatenate([[i] * self.objSpace.width for i in range(0, self.objSpace.height)])

        if type == "random_sample": # randomly pick n choices from the all possibilities
            sampleCount = (int)(len(pathx) * sparsity)
            index = np.random.choice(pathx.shape[0], sampleCount, replace=False)

            x = pathx[index]
            y = pathy[index]


        elif type == "pick_percent": # will take sensations with given percentage of them with features
            sampleCount = (int)(len(pathx) * sparsity)
            sampleWithFeatureCount = (int)(sampleCount * featurePerc)
            sampleWithoutFeatureCount = sampleCount - sampleWithFeatureCount

            if sampleWithFeatureCount==0:
                raise RuntimeError("Sample with feature count is ZERO !!!")

            res = np.zeros(shape=(sampleCount, 2),dtype=int)
            i=0
            u=0
            withFeatures = 0
            withoutFeatures = 0
            np.random.shuffle(pathx)
            np.random.shuffle(pathy)
            while i<pathx.shape[0]:

                self.agent.move(pathx[i], pathy[i])

                # in one of the directions there is some feature
                f = self.agent.get_feature(Direction.UP) is not None or self.agent.get_feature(Direction.DOWN) is not None\
                    or self.agent.get_feature(Direction.LEFT) is not None or self.agent.get_feature(Direction.RIGHT) is not None

                if f:
                    if withFeatures<sampleWithFeatureCount:
                        res[u][0] = pathx[i]
                        res[u][1] = pathy[i]
                        withFeatures += 1
                        u+=1
                else:
                    if withoutFeatures<sampleWithoutFeatureCount:
                        res[u][0] = pathx[i]
                        res[u][1] = pathy[i]
                        withoutFeatures += 1
                        u+=1

                i+=1
            if withoutFeatures!=sampleWithoutFeatureCount or withFeatures!=sampleWithFeatureCount:
                raise RuntimeError("Wasn't able to generate sensation with given percentage of features!")

            # shuffle them, we don't want to have "with features" mostly at the end - for sparser objects, but uniformly distributed
            np.random.shuffle(res)

        else: #"all" # agent will traverse every position in object space
            pass


        return res

    def CreateSensationStream_sensations(self,sensorDirection, n, w, positionStream):
        stream = []
        # Create scalar encoder to encode features
        p = ScalarEncoderParameters()
        p.size = n
        p.activeBits = w
        p.minimum = 0
        p.maximum = 1
        encoder = ScalarEncoder(p)

        x = positionStream[:,0]
        y = positionStream[:,1]

        for i in range(len(x)):
            self.agent.move(x[i], y[i])
            f = self.agent.get_feature(sensorDirection)
            feature = (('X', 'Y').index(f)+1) if f is not None else 0
            stream.append(([x[i], y[i]], list(encoder.encode(feature).sparse)))
        return stream


    def learn(self, params, repetition):
        """
        Take the steps necessary to reset the experiment before each repetition:
            - Make sure random seed is different for each repetition
            - Create the L2-L4-L6a network
            - Load objects used by the experiment
            - Learn all objects used by the experiment
        """
        print(params["name"], ":", repetition)
        self.debug = params.get("debug", False)
        self.numLearningPoints = params["num_learning_points"]
        self.numOfSensations = params["num_sensations"]

        L2Params = params["l2_params"]
        L4Params = params["l4_params"]
        L6aParams = params["l6a_params"]

        self.L4Params = L4Params

        self.sdrSize = L2Params["sdrSize"]

        # Make sure random seed is different for each repetition
        seed = params.get("seed", 42)
        np.random.seed(seed + repetition)
        random.seed(seed + repetition)
        L2Params["seed"] = seed + repetition
        L4Params["seed"] = seed + repetition
        L6aParams["seed"] = seed + repetition

        # Configure L6a params
        numModules = L6aParams["moduleCount"]
        L6aParams["scale"] = [params["scale"]] * numModules
        angle = params["angle"] // numModules
        orientation = list(range(angle // 2, angle * numModules, angle))
        L6aParams["orientation"] = np.radians(orientation).tolist()
        L6aParams["cellsPerAxis"] = params["cells_per_axis"]

        # Create four column L2-L4-L6a network
        self.network = L2_L4_L6_Network(numColumns=4,
                                    L2Params=L2Params,
                                    L4Params=L4Params,
                                    L6aParams=L6aParams,
                                    repeat=self.numLearningPoints,
                                    logCalls=self.debug)

        # data for dash plots
        self.network.network.updateDataStreams = self.updateDataStreams
        self.network.network.bakePandaData = self.bakePandaData # bake or not bake pandaData

        sampleSize = L4Params["sampleSize"]
        columnCount = L4Params["columnCount"]

        # Make sure w is odd per encoder requirement
        sampleSize = sampleSize if sampleSize % 2 != 0 else sampleSize + 1

        # Load objects
        self.learnedObjectNames = ["cup", "palmpilot", "a", "b", "boat"]#["simple1", "simple2", "simple3"]


        streamForAllColumns = {}
        self.sensations = {}
        for obj in self.learnedObjectNames:
            self.loadObject(obj) # loads object into object space
            self.sensations[obj] = {}

            posStream = self.CreateSensationStream_positions(type="pick_percent", sparsity= self.numOfSensations / (self.objectSpaceSize*self.objectSpaceSize) , featurePerc=0.5)

            self.sensations[obj][0] = self.CreateSensationStream_sensations(sensorDirection = Direction.UP,
                                                        w=sampleSize, n=columnCount, positionStream=posStream)
            self.sensations[obj][1] = self.CreateSensationStream_sensations(sensorDirection=Direction.DOWN,
                                                         w=sampleSize, n=columnCount, positionStream=posStream)
            self.sensations[obj][2] = self.CreateSensationStream_sensations(sensorDirection=Direction.LEFT,
                                                         w=sampleSize, n=columnCount, positionStream=posStream)
            self.sensations[obj][3] = self.CreateSensationStream_sensations(sensorDirection=Direction.RIGHT,
                                                         w=sampleSize, n=columnCount, positionStream=posStream)

            streamForAllColumns[obj] = [self.sensations[obj][0], self.sensations[obj][1],
                                            self.sensations[obj][2], self.sensations[obj][3]] # we are feeding now just for one column

            if PLOT_LEARN_SEQUENCE:
                self.plotStream(self.sensations[obj][0])

        # Learn objects
        self.network.learn(streamForAllColumns)

    def plotStream(self, stream):

        for s in stream:
            # Plotting and visualising environment-------------------------------------------
            if (
                    self.fig_environment == None or isNotebook()
            ):  # create figure only if it doesn't exist yet or we are in interactive console
                self.fig_environment, _ = plt.subplots(nrows=1, ncols=1, figsize=(6, 4))
            else:
                self.fig_environment.axes[0].clear()

            plotEnvironment(self.fig_environment.axes[0], "Environment", self.objSpace, s[0])
            self.fig_environment.canvas.draw()

            plt.show(block=False)
            plt.pause(0.001)  # delay is needed for proper redraw

    def updateDataStreams(self):

        # for first column
        for col in [0, 1, 2, 3]:
            self.network.network.UpdateDataStream("L2ActiveCellCnt_"+str(col), len(self.network.getL2Representations()[col]))
            self.network.network.UpdateDataStream("L4PredictedCellCnt_"+str(col), len(self.network.getL4PredictedCells()[col]))
            self.network.network.UpdateDataStream("L4ActiveCellCnt_"+str(col), len(self.network.getL4Representations()[col]))
            self.network.network.UpdateDataStream("L6ActiveCellCnt_"+str(col), len(self.network.getL6aRepresentations()[col]))

    def infer(self, objectName):
        """
        For each iteration try to infer the object.

        :param objectName: Object name to infer
        :return: stats of inferrence
        """

        #sensations = copy.deepcopy(self.learnedObjects[objectName])

        #rng = np.random.default_rng()
        # indexes = random.sample(range(0, len(sensations[0])), self.numOfSensations)
        #
        # sampledSensations = []
        # for k, s in sensations.items():# for each sensor sensation
        #     s = np.array(s, dtype=object)
        #     sampledSensations.append(s[np.array(np.array(indexes))])

        sampleSize = self.L4Params["sampleSize"]
        columnCount = self.L4Params["columnCount"]

        # self.inferSensations = {}
        # for obj in self.learnedObjectNames:
        #     self.loadObject(obj)  # loads object into object space
        #     self.inferSensations[obj] = {}
        #
        #     posStream = self.CreateSensationStream_positions(type="pick_percent", sparsity=0.1, featurePerc=0.5)
        #
        #     self.inferSensations[obj][0] = self.CreateSensationStream_sensations(sensorDirection=Direction.UP,
        #                                                              w=sampleSize, n=columnCount, positionStream=posStream)
        #     self.inferSensations[obj][1] = self.CreateSensationStream_sensations(sensorDirection=Direction.DOWN,
        #                                                              w=sampleSize, n=columnCount, positionStream=posStream)
        #     self.inferSensations[obj][2] = self.CreateSensationStream_sensations(sensorDirection=Direction.LEFT,
        #                                                              w=sampleSize, n=columnCount, positionStream=posStream)
        #     self.inferSensations[obj][3] = self.CreateSensationStream_sensations(sensorDirection=Direction.RIGHT,
        #                                                              w=sampleSize, n=columnCount, positionStream=posStream)
        #
        # if PLOT_INFER_SEQUENCE:
        #     self.plotStream(self.inferSensations[0]) # plot just first, same as the others

        #self.network.sendReset() do not call it there, see l2_l4_l6_Network.py line 214



        self.inferSensations = self.sensations # learned sensations are identical with inferring sensations

        # Collect all statistics for every inference.
        # See L246aNetwork._updateInferenceStats
        stats = defaultdict(list)
        self.network.infer(sensations=self.inferSensations[objectName], stats=stats, objname=objectName)
        stats.update({"name": objectName})

        return stats

    def PlotSensations(self, obj):
        self.loadObject(obj)

        # Plotting and visualising environment-------------------------------------------
        if (
                self.fig_environment == None or isNotebook()
        ):  # create figure only if it doesn't exist yet or we are in interactive console
            self.fig_environment, _ = plt.subplots(nrows=1, ncols=1, figsize=(6, 4))
        else:
            self.fig_environment.axes[0].clear()

        s1 = [x[0] for x in self.sensations[obj][0]]
        s2 = [x[0] for x in self.inferSensations[obj][0]]

        plotSensations(self.fig_environment.axes[0], "Sensations", self.objSpace, s1, s2)
        self.fig_environment.canvas.draw()

        plt.show(block=True)


if __name__ == "__main__":
    registerAllAdvancedRegions()

    with open("parameters.cfg", "r") as f:
        parameters = eval(f.read())

    experiment = Experiment(objectSpaceSize=20) # "map size" - adjust to fit objects into object space

    experiment.learn(parameters, 0)

    print("Learning done, begin inferring")

    for obj in ["cup", "palmpilot", "a", "b", "boat"]:
        stats = experiment.infer(objectName=obj)

        if 1 in stats['Correct classification']:
            print("Correctly classified!!")

    printedStats = json.dumps(stats, indent=4)
    with open("stats.json", "w") as f:
        f.write(printedStats)


    experiment.PlotSensations('boat')



